# -*- coding: utf-8 -*-
"""Weather PA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yqniAaF0xdM6PPv3KLhLO9JVSOrJ9ncw
"""

import pandas as pd
weather = pd.read_csv("WeatherPrediction.csv",index_col="DATE")

weather

"""null pct gives the percentage of null values"""

null_pct = weather.apply(pd.isnull).sum()/weather.shape[0]
null_pct

weather.apply(pd.isnull).sum()

"""tells us how many columns are less than 50% null values"""

valid_columns = weather.columns[null_pct <.05]
valid_columns

"""from next time it will only take valid_columns in use"""

weather = weather[valid_columns].copy()

weather.columns = weather.columns.str.lower()
#to make all columns value in lower case

weather

weather = weather.ffill()

weather.apply(pd.isnull).sum()
#to print all non null values

weather.dtypes

weather.index

weather.index = pd.to_datetime(weather.index)
#to convert object datetime into real date time

weather.index

weather.index.year.value_counts().sort_index()
#to print years in order and to check is there is gap or not between data

weather["snwd"].plot()
#to check snow accumulation

weather

weather["target"] = weather.shift(-1)["tmax"]
#to predict tommorow's data

weather

weather = weather.ffill()
#to fill yesterday values bcz last columns last row value has a null value

weather

from sklearn.linear_model import Ridge
rr = Ridge(alpha = .1)
#alpha control how much coeffiecent are shrunk for account with collinearity

weather.corr()
#to check correlation

predictors = weather.columns[~weather.columns.isin(["target","name","station"])]
# to print values instead of target,name, and station

predictors

def backtest(weather, model, predictors, start=3650, step=90):
    all_predictions = []

    for i in range(start, weather.shape[0], step):
        train = weather.iloc[:i,:]
        test = weather.iloc[i:(i+step),:]

        model.fit(train[predictors], train["target"])

        preds = model.predict(test[predictors])
        preds = pd.Series(preds, index=test.index)
        combined = pd.concat([test["target"], preds], axis=1)
        combined.columns = ["actual", "prediction"]
        combined["diff"] = (combined["prediction"] - combined["actual"]).abs()

        all_predictions.append(combined)
    return pd.concat(all_predictions)

predictions = backtest(weather, rr, predictors)

predictions

from sklearn.metrics import mean_absolute_error
mean_absolute_error(predictions["actual"],predictions["prediction"])

predictions["diff"].mean()

def pct_diff(old,new):
  return (new - old)/old
def compute_rolling(weather,horizon,col):
  label = f"rolling_{horizon}_{col}"
  weather[label] = weather[col].rolling(horizon).mean()
  weather[f"{label}_pct"] = pct_diff(weather[label],weather[col])
  return weather
rolling_horizons = [3,14]
for horizon in rolling_horizons:
  for col in ["tmax","tmin","prcp"]:
    weather = compute_rolling(weather,horizon,col)

weather

weather=weather.iloc[14:,:]

weather

weather=weather.fillna(0)
#to fill null values by 0

def expand_mean(df):
  return df.expanding(1).mean()
for col in ["tmax","tmin","prcp"]:
  weather[f"month_avg{col}"] = weather[col].groupby(weather.index.month,group_keys=False).apply(expand_mean)
  weather[f"day_avg_{col}"] = weather[col].groupby(weather.index.day_of_year, group_keys=False).apply(expand_mean)

weather

predictors = weather.columns[~weather.columns.isin(["target","name","station"])]

predictors

predictions = backtest(weather, rr, predictors)

mean_absolute_error(predictions["actual"],predictions["prediction"])

predictions.sort_values("diff",ascending=False)

weather.loc["1990-03-07":"1990-03-17"]

predictions["diff"].round().value_counts().sort_index().plot()

predictions

